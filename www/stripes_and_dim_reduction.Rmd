---
title: "Stripe space and dimension reduction"
author: "W. Bauer, R. Grdina"
date: "October 25, 2015"
output: html_document
---

### Terminology

The *null space* of a matrix, $S$, consists of all vectors, $v$, such that $Sv = 0$. It is called a *space* because it is closed under vector addition and multiplication by scalars. That is, if $Sv_i = 0$ for $i=1, \ldots, n$ and $\alpha_1, \ldots \alpha_n$ are scalars, then $S(\alpha_1v_1 + \ldots + \alpha_nv_n)= 0$ as well. This is easily seen since$$S(\alpha_1v_1 + \ldots + \alpha_nv_n)= \alpha_1Sv_1 + \ldots + \alpha_nSv_n \\ = \alpha_10 + \ldots + \alpha_n0 \\ = 0.$$

A matrix is *singular* if its null space includes vectors other than the vector of all zeros. If a matrix is singular, then its null space is of infinite extent because, for example, you can multiply by an arbitrarily large scalar and remain in the space.

The tomography problems of interest here are characterized by incomplete information. That is to say, the measured data does not uniquely determine an image. In the formal terminology of the preceding paragraphs, the system matrices of interest are singular. Hence, if $S$ is a system matrix and $Sb = \tau$, then for any $v$ in the null space of $S$,$$S(b+v)=Sb+Sv=Sb+0=\tau.$$Thus there is an infinite set of "images" which result in precisely the same times of flight.

The total time of flight along a path is unaffected if time is subtracted from one segment of the path and the same amount added at another. This is the origin of the so-called "stripe space" as was explained in detail in a [previous note](S_kernel_etc.html). The stripe space is always contained in the null space of the associated system matrix. The null space itself may be strictly larger, but it cannot be smaller.

The stripe space corresponds to images in which all pixels in a given column have the same value, hence form a stripe, and such that sum of the values of all pixels is zero. It is easily verified that such images are closed under componentwise addition and multiplication by scalars, hence form a vector space.

Two vectors, $u$ and $v$, are *orthogonal* if their dot product, $u \bullet v$, is zero. If a vector, $u$, is orthogonal to *every* $v$ in the stripe space, $u$ is said to be in the *orthogonal complement* of the stripe space. The orthogonal complement of the stripe space is, itself, a vector space. The proof follows directly from definitions.

The *projection* of a vector $v$ onto a vector space is the closest point to $v$ in that space, where "closest" means in the sense of least squares, i.e., in the sense of Euclidean distance. The operation of projecting a vector onto a space can be represented by a matrix. The details can be found in [this note](projection_regularization), where it is also shown that if $P$ is a projection matrix, $P^2 = P$, and $P^T = P$.

### Application

Let $P$ be the matrix representing projection onto the stripe space. Since the stripe space is contained in the null space of the system matrix, $S$, $SPb=0$ for all vectors, $b$. Also, for any vector, $b$, $b = Pb + (I-P)b$ hence$$Sb = S\left(Pb + (I-P)b)\right)\\= SPb + S(I-P)b\\= 0 + S(I-P)b\\=S(I-P)b.$$Thus $b$ and $(I-P)b$ have the precisely the same times of flight. They cannot be distinguished by time-of-flight data.

Note that $(I-P)b$ is in the orthogonal complement of the stripe space since, letting $Pv$ be an arbitrary member of the stripe space,$$(I-P)b \bullet Pv = b^T(I-P)^TPv\\=b^T(I^T-P^T)Pv\\=b^T(I-P)Pv\\=b^T(P-P^2)v\\=b^T(P-P)v\\=b^T(0)v\\=0.$$In fact, $I-P$ represents projection onto the orthogonal complement of the stripe space. We'll omit the proof that $I-P$ is a projection, i.e., maps to the closest point. The proof is straightforward and uses the same properties of $P$ as were used above.

The following shows an image, $b$, from our phantom thigh and its projection, $(I-P)b$, on the orthogonal complement of the stripe space.

```{r fig.show='hold', fig.align='center', echo=FALSE}
img <- as.matrix(read.csv("../data/pixelized_thigh_section.csv", comment.char = "#"))
ap <- read.csv("../data/acoustic_properties_thigh.csv")
for(id in unique(as.vector(img))){
  idx <- img==id 
  img[idx] <- ap[ap$ID==id, "speed"]}
img <- 1/img
width <- nrow(img)
height <- ncol(img)
# Subtract row means
img1 <- img
for(i in 1:nrow(img))img1[i,] <- img[i,]-mean(img[i,])
# Add projection on normalized constant image
M <- matrix(1/sqrt(height*width), width, height)
img1 <- img1 + M * sum(M*img)
# Diplay:
par(mfrow=c(2,1))
image(x=.5*(1:width), y=.5*(1:height), z=img, xlab="x (mm)", ylab="y (mm)", main="Original image")
image(x=.5*(1:width), y=.5*(1:height), z=img1, xlab="x (mm)", ylab="y (mm)", main="Projection onto the orthogonal complement\nof the stripe space")
par(mfrow=c(1,1))
```

(Note that it is the *absence* of the stripe space component which is responsible for the artifacts in the projection. If the stripe space component were added back in, the artifacts would disappear and the original image recovered.)

The correlation of the image with its projection is about 75%. That is, about 25% of the image lies in the stripe space. As shown above, the original image and its projection will yield precisely the same times of flight. Hence, time of flight data contain no information about the component of an image which lies in the stripe space. With time of flight data alone, the best we can hope for is recovery of the projection of an image on the orthogonal complement of the stripe space. 

In this case, however, there are about 6 times as many unknowns, 61x365 pixels, as there are equations, 61x61 times of flight. The stripe space has dimension 364, hence its orthogonal complement has dimension 61x365-364. Thus, projection on the orthogonal complement reduces the effective number of unknowns by very little, from 61x365 to 61x365-364 ~ 60x365. The ratio of unknowns to equations is barely changed.

In the projected image, the general anatomy is apparent despite the artifacts. If the projected image could be even approximately recovered, there's the chance a secondary procedure could improve it significantly. To that end, we would like to discover a space of low dimension in which good approximations to a projected image could be found.

If, for example, 8x8 non-overlapping areas of projected images were adequately approximated by linear combinations of 10 patterns (e.g., by their first 10 principal components) the number of unknowns would be reduced by a factor of 64/10 = 6.4, which is about what would be needed for the number of unknowns to match the number of equations in this case. Moreover, the resulting system of equations would remain sparse. This typifies the strategy we're pursuing at present.


